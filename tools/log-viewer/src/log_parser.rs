//! Log file parser for tracing JSON output
//!
//! Parses pretty-printed JSON logs generated by context-trace's tracing_utils.
//! Each JSON object may span multiple lines with indentation.

use once_cell::sync::Lazy;
use regex::Regex;
use serde::{
    Deserialize,
    Serialize,
};
use std::collections::HashMap;
use ts_rs::TS;

// Regex to strip ANSI escape codes
static ANSI_REGEX: Lazy<Regex> =
    Lazy::new(|| Regex::new(r"\x1b\[[0-9;]*m").unwrap());

// Regex to parse panic location from message: "panicked at <file>:<line>:<col>:"
static PANIC_LOCATION_REGEX: Lazy<Regex> =
    Lazy::new(|| Regex::new(r"panicked at ([^:]+):(\d+):(\d+):").unwrap());

// Regex to parse assertion diff header: "assertion failed: `(left == right)` ... Diff < left / right > :"
// Uses (?s) for DOTALL mode so . matches newlines
// Note: there's a space before the colon in the actual format
static ASSERTION_DIFF_REGEX: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"(?s)assertion failed: `\(left == right\)`.*?Diff < (\w+) / (\w+) >\s*:\s*(.+)").unwrap()
});

/// Strip ANSI escape codes from a string
fn strip_ansi_codes(s: &str) -> String {
    ANSI_REGEX.replace_all(s, "").to_string()
}

/// Parse panic location from message like "panicked at file.rs:123:5: assertion..."
fn parse_panic_location(message: &str) -> Option<(String, u32, u32)> {
    PANIC_LOCATION_REGEX.captures(message).map(|caps| {
        let file = caps.get(1).unwrap().as_str().to_string();
        let line: u32 = caps.get(2).unwrap().as_str().parse().unwrap_or(0);
        let col: u32 = caps.get(3).unwrap().as_str().parse().unwrap_or(0);
        (file, line, col)
    })
}

/// Parsed assertion diff data
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export, export_to = "../frontend/src/types/generated/")]
pub struct AssertionDiff {
    pub title: String,
    pub left_label: String,
    pub right_label: String,
    pub left_value: String,
    pub right_value: String,
}

/// Parse assertion diff from message
/// Format: "assertion failed: `(left == right)` Diff < left / right >: <value\n<value\n>value"
fn parse_assertion_diff(message: &str) -> Option<AssertionDiff> {
    let captures = ASSERTION_DIFF_REGEX.captures(message)?;
    let left_label = captures.get(1)?.as_str().to_string();
    let right_label = captures.get(2)?.as_str().to_string();
    let diff_content = captures.get(3)?.as_str();

    // Parse diff lines: lines starting with < are left, > are right
    let mut left_lines = Vec::new();
    let mut right_lines = Vec::new();

    for line in diff_content.lines() {
        if let Some(rest) = line.strip_prefix('<') {
            left_lines.push(rest.to_string());
        } else if let Some(rest) = line.strip_prefix('>') {
            right_lines.push(rest.to_string());
        }
    }

    Some(AssertionDiff {
        title: "assertion failed: `(left == right)`".to_string(),
        left_label,
        right_label,
        left_value: left_lines.join("\n"),
        right_value: right_lines.join("\n"),
    })
}

/// A parsed log entry
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export, export_to = "../frontend/src/types/generated/")]
pub struct LogEntry {
    /// Entry index (1-based)
    pub line_number: usize,
    /// Log level (TRACE, DEBUG, INFO, WARN, ERROR)
    pub level: String,
    /// Timestamp string
    pub timestamp: Option<String>,
    /// The log message
    pub message: String,
    /// Event type (event, span_enter, span_exit, span_new, span_close)
    pub event_type: String,
    /// Span name (if this is a span event)
    pub span_name: Option<String>,
    /// Indentation depth (number of parent spans)
    pub depth: usize,
    /// Additional fields (preserves structured JSON values)
    #[ts(type = "Record<string, unknown>")]
    pub fields: HashMap<String, serde_json::Value>,
    /// Source file location (from tracing macro)
    pub file: Option<String>,
    /// Source line number (from tracing macro)
    pub source_line: Option<u32>,
    /// Panic file location (from panic info, points to actual assertion)
    pub panic_file: Option<String>,
    /// Panic line number
    pub panic_line: Option<u32>,
    /// Parsed assertion diff (for failed assertions)
    pub assertion_diff: Option<AssertionDiff>,
    /// Stack trace (for panics)
    pub backtrace: Option<String>,
    /// Raw JSON content (pretty-printed)
    pub raw: String,
}

/// Raw JSON structure from tracing-subscriber
#[derive(Debug, Deserialize)]
struct TracingJson {
    timestamp: Option<String>,
    level: Option<String>,
    fields: Option<serde_json::Value>,
    target: Option<String>,
    span: Option<SpanInfo>,
    spans: Option<Vec<SpanInfo>>,
    #[serde(rename = "filename")]
    file: Option<String>,
    #[serde(rename = "line_number")]
    line: Option<u32>,
}

#[derive(Debug, Deserialize)]
struct SpanInfo {
    name: Option<String>,
    #[serde(flatten)]
    fields: HashMap<String, serde_json::Value>,
}

/// Parser for log files
pub struct LogParser;

impl LogParser {
    pub fn new() -> Self {
        Self
    }

    /// Parse log content into structured entries
    ///
    /// Handles both pretty-printed JSON (multi-line) and NDJSON formats.
    /// Uses serde_json's streaming deserializer to parse consecutive JSON objects.
    pub fn parse(
        &self,
        content: &str,
    ) -> Vec<LogEntry> {
        let mut entries = Vec::new();

        // Use streaming deserializer to handle multiple JSON objects
        let stream = serde_json::Deserializer::from_str(content)
            .into_iter::<TracingJson>();

        for (index, result) in stream.enumerate() {
            let entry_num = index + 1;

            match result {
                Ok(json) => {
                    // For pretty JSON, we don't have exact line info, so use entry index
                    entries.push(self.json_to_entry(entry_num, &json));
                },
                Err(e) => {
                    // Log parse error as a fallback entry
                    entries.push(LogEntry {
                        line_number: entry_num,
                        level: "ERROR".to_string(),
                        timestamp: None,
                        message: format!("JSON parse error: {}", e),
                        event_type: "error".to_string(),
                        span_name: None,
                        depth: 0,
                        fields: HashMap::new(),
                        file: None,
                        source_line: None,
                        panic_file: None,
                        panic_line: None,
                        assertion_diff: None,
                        backtrace: None,
                        raw: format!("Parse error at entry {}", entry_num),
                    });
                    // Stop on parse errors to avoid cascading failures
                    break;
                },
            }
        }

        entries
    }

    fn json_to_entry(
        &self,
        line_number: usize,
        json: &TracingJson,
    ) -> LogEntry {
        let level = json.level.clone().unwrap_or_else(|| "INFO".to_string());

        // Extract message and event type from fields
        let (message, event_type, backtrace) =
            self.extract_message_and_type(&json);

        // Extract span name
        let span_name =
            json.span.as_ref().and_then(|s| s.name.clone()).or_else(|| {
                json.spans
                    .as_ref()
                    .and_then(|spans| spans.last())
                    .and_then(|s| s.name.clone())
            });

        // Calculate depth from spans array
        let depth = json.spans.as_ref().map(|s| s.len()).unwrap_or(0);

        // Extract additional fields - preserve JSON structure for typed values
        let mut fields: HashMap<String, serde_json::Value> = HashMap::new();
        if let Some(field_value) = &json.fields {
            if let Some(obj) = field_value.as_object() {
                for (key, value) in obj {
                    // Skip fields we handle separately
                    if key != "message"
                        && key != "backtrace"
                        && key != "panic_file"
                        && key != "panic_line"
                        && key != "panic_column"
                    {
                        fields.insert(key.clone(), value.clone());
                    }
                }
            }
        }

        // Also extract fields from current span
        if let Some(span) = &json.span {
            for (key, value) in &span.fields {
                if key != "name" {
                    fields.insert(key.clone(), value.clone());
                }
            }
        }

        // Get tracing macro location (where the log statement is)
        let file = json.file.clone();
        let source_line = json.line;

        // Get panic location - either from fields or parsed from message
        let mut panic_file = None;
        let mut panic_line = None;

        // First check for panic location fields (from new panic hook)
        if let Some(field_value) = &json.fields {
            if let Some(obj) = field_value.as_object() {
                if let Some(pf) = obj.get("panic_file") {
                    if let Some(s) = pf.as_str() {
                        panic_file = Some(s.to_string());
                    }
                }
                if let Some(pl) = obj.get("panic_line") {
                    if let Some(n) = pl.as_u64() {
                        panic_line = Some(n as u32);
                    }
                }
            }
        }

        // If no panic fields, try to parse from message (for old log files)
        if panic_file.is_none() && message.contains("panicked at") {
            if let Some((pf, pl, _col)) = parse_panic_location(&message) {
                panic_file = Some(pf);
                panic_line = Some(pl);
            }
        }

        // Parse assertion diff from message if this is a panic
        let assertion_diff = parse_assertion_diff(&message);

        LogEntry {
            line_number,
            level: level.clone(),
            timestamp: json.timestamp.clone(),
            message: message.clone(),
            event_type,
            span_name,
            depth,
            fields,
            file,
            source_line,
            panic_file,
            panic_line,
            assertion_diff,
            backtrace,
            // Generate a compact summary for raw field
            raw: format!("[{}] {}", level, message),
        }
    }

    fn extract_message_and_type(
        &self,
        json: &TracingJson,
    ) -> (String, String, Option<String>) {
        let mut message = String::new();
        let mut event_type = "event".to_string();
        let mut backtrace = None;

        if let Some(fields) = &json.fields {
            if let Some(obj) = fields.as_object() {
                // Check for message field
                if let Some(msg) = obj.get("message") {
                    message = match msg {
                        serde_json::Value::String(s) => strip_ansi_codes(s),
                        other => strip_ansi_codes(&other.to_string()),
                    };
                }

                // Check for backtrace field
                if let Some(bt) = obj.get("backtrace") {
                    backtrace = match bt {
                        serde_json::Value::String(s) => Some(s.clone()),
                        other => Some(other.to_string()),
                    };
                }
            }
        }

        // Detect span events from message content
        if message.contains("new") || message.contains("enter") {
            // Check if this is a span enter/new event
            if let Some(span) = &json.span {
                if span.name.is_some() {
                    if message.contains("new") {
                        event_type = "span_new".to_string();
                    } else {
                        event_type = "span_enter".to_string();
                    }
                }
            }
        } else if message.contains("close") || message.contains("exit") {
            if json.span.is_some() {
                if message.contains("close") {
                    event_type = "span_exit".to_string();
                } else {
                    event_type = "span_exit".to_string();
                }
            }
        }

        // If message is empty, use target or generate a description
        if message.is_empty() {
            if let Some(span) = &json.span {
                if let Some(name) = &span.name {
                    message = format!("Span: {}", name);
                    event_type = "span_enter".to_string();
                }
            }
            if message.is_empty() {
                message = json
                    .target
                    .clone()
                    .unwrap_or_else(|| "Unknown".to_string());
            }
        }

        (message, event_type, backtrace)
    }
}

impl Default for LogParser {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_event() {
        let parser = LogParser::new();
        let content = r#"{"timestamp":"2024-01-01T00:00:00.000000Z","level":"DEBUG","fields":{"message":"Processing token"},"target":"test","filename":"src/main.rs","line_number":42}"#;
        let entries = parser.parse(content);

        assert_eq!(entries.len(), 1);
        let entry = &entries[0];
        assert_eq!(entry.level, "DEBUG");
        assert_eq!(entry.event_type, "event");
        assert_eq!(entry.message, "Processing token");
        assert_eq!(entry.file.as_deref(), Some("src/main.rs"));
        assert_eq!(entry.source_line, Some(42));
    }

    #[test]
    fn test_parse_span_enter() {
        let parser = LogParser::new();
        let content = r#"{"timestamp":"2024-01-01T00:00:00.000000Z","level":"INFO","fields":{"message":"enter"},"target":"test","span":{"name":"my_function"}}"#;
        let entries = parser.parse(content);

        assert_eq!(entries.len(), 1);
        let entry = &entries[0];
        assert_eq!(entry.level, "INFO");
        assert_eq!(entry.event_type, "span_enter");
        assert_eq!(entry.span_name.as_deref(), Some("my_function"));
    }

    #[test]
    fn test_parse_span_close() {
        let parser = LogParser::new();
        let content = r#"{"timestamp":"2024-01-01T00:00:00.000000Z","level":"INFO","fields":{"message":"close"},"target":"test","span":{"name":"my_function"}}"#;
        let entries = parser.parse(content);

        assert_eq!(entries.len(), 1);
        let entry = &entries[0];
        assert_eq!(entry.level, "INFO");
        assert_eq!(entry.event_type, "span_exit");
        assert_eq!(entry.span_name.as_deref(), Some("my_function"));
    }

    #[test]
    fn test_calculate_depth() {
        let parser = LogParser::new();
        // Test depth from spans array
        let entry1 =
            r#"{"level":"INFO","fields":{"message":"test"},"spans":[]}"#;
        let entry2 = r#"{"level":"INFO","fields":{"message":"test"},"spans":[{"name":"a"}]}"#;
        let entry3 = r#"{"level":"INFO","fields":{"message":"test"},"spans":[{"name":"a"},{"name":"b"}]}"#;

        let entries =
            parser.parse(&format!("{}\n{}\n{}", entry1, entry2, entry3));
        assert_eq!(entries[0].depth, 0);
        assert_eq!(entries[1].depth, 1);
        assert_eq!(entries[2].depth, 2);
    }
}
